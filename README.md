# ğŸ“ Orchid International College - AI Assistant

A conversational AI chatbot powered by **RAG (Retrieval-Augmented Generation)** techniques to provide accurate information about Orchid International College.

![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-121212?style=for-the-badge)
![Ollama](https://img.shields.io/badge/Ollama-000000?style=for-the-badge)

## âœ¨ Features

- ğŸ¤– **AI-Powered Responses** - Uses Llama 3.2 via Ollama for natural conversations
- ğŸ“š **RAG Architecture** - Retrieves relevant context from college documents
- ğŸ” **Semantic Search** - ChromaDB vector store with HuggingFace embeddings
- ğŸ›¡ï¸ **Security** - Built-in prompt injection protection
- ğŸ’¬ **Chat History** - Maintains conversation context
- ğŸ¨ **Modern UI** - Beautiful Streamlit interface

## ğŸ“ Project Structure

```
RAG-Chat/
â”œâ”€â”€ app.py                 # Streamlit UI application
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ answer.py          # RAG question-answering logic
â”‚   â”œâ”€â”€ ingest.py          # Document ingestion pipeline
â”‚   â”œâ”€â”€ evaluation.py      # MRR evaluation module
â”‚   â””â”€â”€ security.py        # Prompt injection detection
â”œâ”€â”€ OIC_Website/           # Knowledge base (Markdown files)
â”‚   â”œâ”€â”€ 01_About_Us.md
â”‚   â”œâ”€â”€ 02_BSc_CSIT.md
â”‚   â”œâ”€â”€ 03_BCA.md
â”‚   â”œâ”€â”€ 04_BITM.md
â”‚   â”œâ”€â”€ 05_BBM.md
â”‚   â”œâ”€â”€ 06_BBS.md
â”‚   â”œâ”€â”€ 07_BSW.md
â”‚   â””â”€â”€ 08_Contact.md
â”œâ”€â”€ vector_db/             # ChromaDB vector store (generated)
â”œâ”€â”€ evaluation_data.json   # Test queries for MRR evaluation
â”œâ”€â”€ .env                   # Environment variables
â””â”€â”€ requirements.txt       # Python dependencies
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- [Ollama](https://ollama.com/download) installed and running

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/RAG-Chat.git
   cd RAG-Chat
   ```

2. **Create virtual environment**
   ```bash
   python -m venv .venv
   .venv\Scripts\activate  # Windows
   # source .venv/bin/activate  # Linux/Mac
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Pull the Ollama model**
   ```bash
   ollama pull llama3.2
   ```

5. **Ingest documents** (create vector embeddings)
   ```bash
   python core/ingest.py
   ```

6. **Run the application**
   ```bash
   streamlit run app.py
   ```

7. Open your browser at `http://localhost:8501`

## âš™ï¸ Configuration

Create a `.env` file in the root directory:

```env
OLLAMA_MODEL=llama3.2
```

### Available Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `OLLAMA_MODEL` | `llama3.2` | Ollama model to use for generation |

## ğŸ“– Adding Knowledge

1. Add your Markdown files to the `OIC_Website/` directory
2. Run the ingestion script:
   ```bash
   python core/ingest.py
   ```
3. Restart the Streamlit app

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Frontend** | Streamlit |
| **LLM** | Ollama (Llama 3.2) |
| **Embeddings** | HuggingFace (all-MiniLM-L6-v2) |
| **Vector Store** | ChromaDB |
| **Framework** | LangChain |

## ğŸ“ Usage

Simply type your question in the chat input:

- "What programs does Orchid International College offer?"
- "Tell me about BSc CSIT program"
- "What are the admission requirements?"
- "How can I contact the college?"

The assistant will retrieve relevant information from the knowledge base and provide accurate answers.

## ğŸ”’ Security

The chatbot includes built-in protection against:
- Prompt injection attacks
- Jailbreak attempts
- Role manipulation

## ï¿½ RAG Evaluation (MRR Accuracy)

The project includes a comprehensive evaluation module to measure retrieval quality using **Mean Reciprocal Rank (MRR)**.

### What is MRR?

MRR (Mean Reciprocal Rank) measures how well the retrieval system ranks relevant documents:
- **MRR = 1.0**: Relevant document is always first
- **MRR = 0.5**: Relevant document is at position 2 on average
- **MRR = 0.33**: Relevant document is at position 3 on average

### Running Evaluation

```bash
# Run the full MRR evaluation
python core/evaluation.py
```

### Output Example

```
============================================================
            RAG EVALUATION REPORT - MRR ACCURACY
============================================================

ğŸ“Š SUMMARY METRICS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Mean Reciprocal Rank (MRR): 0.8500
  Hit Rate:                   93.33%
  Total Queries:              15
  Hits (relevant found):      14
  Misses (not found):         1
```

### Customizing Test Data

Edit `evaluation_data.json` to add your own test queries:

```json
[
  {
    "query": "Your test question here",
    "relevant_sources": ["expected_file.md"]
  }
]
```

### Using Evaluation in Code

```python
from core.evaluation import evaluate_mrr, evaluate_mrr_at_k

# Run basic evaluation
report = evaluate_mrr(k=10)
print(f"MRR Score: {report.mrr_score}")

# Evaluate at different k values
mrr_scores = evaluate_mrr_at_k(k_values=[1, 3, 5, 10])
```

## ï¿½ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¥ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

Made with â¤ï¸ for Orchid International College